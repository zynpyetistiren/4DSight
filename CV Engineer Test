#importing necessary libraries
import numpy as np
import cv2


#reads images
small_img = cv2.imread('Small_area_rotated.png')
starmap = cv2.imread('StarMap.png') 

alpha = 3.1 # Contrast control (1.0-3.0)
beta = 0 # Brightness control (0-100)

#increasing the contrast for better results
small_img = cv2.convertScaleAbs(small_img, alpha=alpha, beta=beta)
starmap = cv2.convertScaleAbs(starmap, alpha=alpha, beta=beta)


# create SIFT detector
sift = cv2.xfeatures2d.SIFT_create()

# find the keypoints and descriptors with SIFT
kp1, des1 = sift.detectAndCompute(small_img,None)
kp2, des2 = sift.detectAndCompute(starmap,None)

FLANN_INDEX_KDTREE = 0
index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
search_params = dict(checks = 50)

#create the descriptor matcher
flann = cv2.FlannBasedMatcher(index_params, search_params)

#detect matches
matches = flann.knnMatch(des1,des2,k=2)

MIN_MATCH_COUNT = 10 #limit keypoint match count for successfully detecting the image(5 star matches needed)

# store all the good matches
good = []
for m,n in matches:
    if m.distance < 0.7*n.distance:
        good.append(m)


if len(good)>MIN_MATCH_COUNT:#there are enough matches and image is found

    #extracting the locations of matched keypoints
    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)#keypoints of small img in good matches 
    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)#keypoints of starmap in good matches 

    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)#finds transformation mask
    matchesMask = mask.ravel().tolist()

    h,w,c = small_img.shape
    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)
    dst = cv2.perspectiveTransform(pts,M)#find the corresponding corner points in the StartMap image
    print(dst)

else:#small image is not found in the StarMap
    print("Not enough matches are found. There are %d matches found but %d needed" % (len(good),MIN_MATCH_COUNT))
